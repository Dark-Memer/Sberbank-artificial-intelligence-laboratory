# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nIGBn_IK6Ikt22qvDG6DTCB-_2-Iev08
"""

# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nIGBn_IK6Ikt22qvDG6DTCB-_2-Iev08
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import sys
sys.path.append('/home/iburenko/SimCLR/')
sys.path.append('/home/iburenko/timm/')
import torch
import numpy as np
import json
import matplotlib.pyplot as plt
#from loader import PETDataset, TransformsSimCLR
from timm import create_model, list_models
from simclr import SimCLR
from simclr.modules import NT_Xent, LARS
from transformers import BertTokenizerFast
from tqdm import tqdm
import umap
from torch.utils.data import DataLoader, Dataset
from itertools import combinations_with_replacement
import cv2
import torchvision
from torch import nn, optim
import argparse
import time
import torchvision.transforms as transforms
from timm import create_model
from PIL import Image, ImageOps, ImageFilter
from torch.utils.tensorboard import SummaryWriter
import math
import json
import torch
from torch.utils.data import Dataset
import torchvision
import numpy as np
from tqdm import tqdm
import cv2
import random

# %matplotlib inline

def off_diagonal(x):
    # return a flattened view of the off-diagonal elements of a square matrix
    n, m = x.shape
    assert n == m
    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()

def adjust_learning_rate(epochs, optimizer, loader, step):
#     max_steps = epochs * len(loader)
#     warmup_steps = 10 * len(loader)
#     base_lr = 32 / 256
#     if step < warmup_steps:
#         lr = base_lr * step / warmup_steps
#     else:
#         step -= warmup_steps
#         max_steps -= warmup_steps
#         q = 0.5 * (1 + math.cos(math.pi * step / max_steps))
#         end_lr = base_lr * 0.001
#         lr = base_lr * q + end_lr * (1 - q)
    lr = 1
    optimizer.param_groups[0]['lr'] = lr * 0.2
    optimizer.param_groups[1]['lr'] = lr * 0.0048

    
class PETDataset(Dataset):
    def __init__(self, train, size=64, transform = True):
        assert train in ['train', 'val']
        self.train = train
        self.resize = torchvision.transforms.Resize(size=size)
        with open('train_val_split.json', 'r') as file:
            self.image_filenames = json.load(file)[train]
        self.all_lens = [len(val) for val in self.image_filenames.values()]
        self.cumsum = np.array([sum(self.all_lens[:i]) for i in range(len(self.all_lens)+1)])
        self.transform = transform
    
    def __len__(self):
        return self.cumsum[-1]

    def __getitem__(self, idx):
        case_id = (idx >= self.cumsum).sum() - 1
        key = list(self.image_filenames.keys())[case_id]
        slice_id = idx - self.cumsum[case_id]
        im = cv2.imread(key+'/'+self.image_filenames[key][slice_id])
        #print(key+'/'+self.image_filenames[key][slice_id])
        #print(im.shape)
        #print(im.type())
        
        im = np.moveaxis(im, -1, 0)
        
        im = self.resize(torch.from_numpy(im))
        im = im.numpy()
        im1 = Image.fromarray((im[1] * 255).astype(np.uint8))
        #print(im1)
        #print(im[1].type())
        
        if self.transform:
            pic1, pic2 = self.transform(im1)
        
        return self._normalize(pic1.reshape(256, 256), 'ct'), self._normalize(pic2.reshape(256, 256), 'ct')
    
    def _normalize(self, image, mode):
        assert mode in ['ct', 'pet']
        mean = 69.1 if mode == 'ct' else 4.7
        std = 55.6 if mode == 'ct' else 18.1
        return (image-mean)/std
    
    

class BarlowTwins(nn.Module):
    def __init__(self):
        super().__init__()
        
        #self.backbone = torchvision.models.resnet50(zero_init_residual=True)
        self.backbone = create_model('wide_resnet50_2', in_chans=1, pretrained=True)
        self.backbone.fc = nn.Identity()

        # projector
        #sizes = [2048] + list(map(int, '8192-8192-8192'.split('-')))
        layers = []

        #for i in range(len(sizes) - 2):
        layers.append(nn.Linear(2048, 4096, bias=False))
        x1 = nn.Linear(2048, 4096, bias=False)

        layers.append(nn.BatchNorm1d(4096))
        x2 = nn.BatchNorm1d(4096)

        layers.append(nn.ReLU(inplace=True))
        x3 = nn.ReLU(inplace=True)

            
      
        layers.append(nn.Linear(4096, 2048, bias=False))
        x4 = nn.Linear(4096, 2048, bias=False)

        self.projector = nn.Sequential(*layers)


        # normalization layer for the representations z1 and z2
        self.bn = nn.BatchNorm1d(2048, affine=False)

    def forward(self, y1, y2):
   
        z1 = self.projector(self.backbone(y1))
        z2 = self.projector(self.backbone(y2))

        # empirical cross-correlation matrix
        c = self.bn(z1).T @ self.bn(z2)

        # sum the cross-correlation matrix between all gpus
        c.div_(32)
        #torch.distributed.all_reduce(c)

        on_diag = torch.diagonal(c).add_(-1).pow_(2).sum()
        off_diag = off_diagonal(c).pow_(2).sum()
        loss = on_diag + 0.0051 * off_diag / 100000
        return loss

class LARS(optim.Optimizer):
    def __init__(self, params, lr, weight_decay=0, momentum=0.9, eta=0.001,
                 weight_decay_filter=False, lars_adaptation_filter=False):
        defaults = dict(lr=lr, weight_decay=weight_decay, momentum=momentum,
                        eta=eta, weight_decay_filter=weight_decay_filter,
                        lars_adaptation_filter=lars_adaptation_filter)
        super().__init__(params, defaults)


    def exclude_bias_and_norm(self, p):
        return p.ndim == 1

    @torch.no_grad()
    def step(self):
        for g in self.param_groups:
            for p in g['params']:
                dp = p.grad

                if dp is None:
                    continue

                if not g['weight_decay_filter'] or not self.exclude_bias_and_norm(p):
                    #print(p.shape)
                    dp = dp.add(p, alpha=g['weight_decay'])

                if not g['lars_adaptation_filter'] or not self.exclude_bias_and_norm(p):
                    param_norm = torch.norm(p)
                    update_norm = torch.norm(dp)
                    one = torch.ones_like(param_norm)
                    q = torch.where(param_norm > 0.,
                                    torch.where(update_norm > 0,
                                                (g['eta'] * param_norm / update_norm), one), one)
                    dp = dp.mul(q)

                param_state = self.state[p]
                if 'mu' not in param_state:
                    param_state['mu'] = torch.zeros_like(p)
                mu = param_state['mu']
                mu.mul_(g['momentum']).add_(dp)

                p.add_(mu, alpha=-g['lr'])

                
class GaussianBlur(object):
    def __init__(self, p):
        self.p = p

    def __call__(self, img):
        if random.random() < self.p:
            sigma = random.random() * 1.9 + 0.1
            return img.filter(ImageFilter.GaussianBlur(sigma))
        else:
            return img


class Solarization(object):
    def __init__(self, p):
        
        self.p = p

    def __call__(self, img):
        if random.random() < self.p:
            return ImageOps.solarize(img)
        else:
            return img

class Transform:
    def __init__(self):
        self.transform = transforms.Compose([
            #transforms.RandomResizedCrop(224, interpolation=Image.BICUBIC),
            #transforms.RandomHorizontalFlip(p=0.5),
#             transforms.RandomApply(
#                 [transforms.ColorJitter(brightness=0.4, contrast=0.4,
#                                         saturation=0.2, hue=0.1)],
#                 p=0.8
#             ),
            #transforms.RandomGrayscale(p=0.2),
            GaussianBlur(p=0.0),
            #Solarization(p=0.0),
            transforms.ToTensor(),
            #transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 #std=[0.229, 0.224, 0.225])
        ])
        self.transform_prime = transforms.Compose([
            #transforms.RandomResizedCrop(224, interpolation=Image.BICUBIC),
            #transforms.RandomHorizontalFlip(p=0.5),
#             transforms.RandomApply(
#                 [transforms.ColorJitter(brightness=0.4, contrast=0.4,
#                                         saturation=0.2, hue=0.1)],
#                 p=0.8
#             ),
            #transforms.RandomGrayscale(p=0.2),
            GaussianBlur(p=1.0),
            #Solarization(p=1.0),
            transforms.ToTensor(),
            #transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                # std=[0.229, 0.224, 0.225])
        ])

    def __call__(self, x):
        y1 = self.transform(x)
        y2 = self.transform_prime(x)
        return y1, y2


device = torch.device('cuda:1')
model = BarlowTwins().to(device)
param_weights = []
param_biases = []
for param in model.parameters():
    if param.ndim == 1:
        param_biases.append(param)
    else:
        param_weights.append(param)
parameters = [{'params': param_weights}, {'params': param_biases}]

optimizer = LARS(parameters, lr=0, weight_decay=1e-6,
                     weight_decay_filter=True,
                     lars_adaptation_filter=True)

dataset = PETDataset('train', 256, transform = Transform())
dataloader = DataLoader(dataset, batch_size=32, num_workers=1)

scaler = torch.cuda.amp.GradScaler()

writer = SummaryWriter('tens_new1')

for epoch in range(500):
    epoch_loss = 0
    for step, (y1, y2) in enumerate(dataloader, start=epoch * len(dataloader)):
        
        y1 = y1.unsqueeze(1)
        y2 = y2.unsqueeze(1)
#         print(torch.cuda.memory_summary(device=device, abbreviated=False))
#         print(y2.size())
#         print(y2.size())
        
        y1, y2 = y1.to(device), y2.to(device)
        adjust_learning_rate(500, optimizer, dataloader, step)
        optimizer.zero_grad()
        
        with torch.cuda.amp.autocast():
            loss = model.forward(y1, y2)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        epoch_loss += loss.item()
        
#         if step%801 == 0 and step != 0:
#             break
        
    print(f'Epoch {epoch+0:03}: | Loss: {epoch_loss/len(dataloader):.5f}')
    
    torch.save(model.state_dict(), '/data/fzhukov/weights_new1/resnet{}.pth'.format(epoch))
    
# save final model
#torch.save(model.module.backbone.state_dict(),'/data/fzhukov/weights/resnet.pth')